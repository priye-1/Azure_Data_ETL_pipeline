{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3451953a-9cdf-460d-8a84-13a7a70f20b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\")\\\n",
    ".csv(\"/mnt/files/Employee.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6f95da-658d-47a8-bd48-27c041ec1d0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: [('Employee_id', 'string'),\n",
      " ('First_Name', 'string'),\n",
      " ('Last_Name', 'string'),\n",
      " ('Gender', 'string'),\n",
      " ('Salary', 'string'),\n",
      " ('Date_of_Birth', 'string'),\n",
      " ('Age', 'string'),\n",
      " ('Country', 'string'),\n",
      " ('Department_id', 'string'),\n",
      " ('Date_of_Joining', 'string'),\n",
      " ('Manager_id', 'string'),\n",
      " ('Currency', 'string'),\n",
      " ('End_Date', 'string')]"
     ]
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5a9c578-4824-4142-ad61-f3e929efc2f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Employee_id: integer (nullable = true)\n",
      " |-- First_name: string (nullable = true)\n",
      " |-- Last_name: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- Date_of_Birth: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Department_id: integer (nullable = true)\n",
      " |-- Date_of_Joining: string (nullable = true)\n",
      " |-- Manager_id: integer (nullable = true)\n",
      " |-- Currency: string (nullable = true)\n",
      " |-- End_Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change data types\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "custom_schema = StructType(\n",
    "    [\n",
    "        StructField(\"Employee_id\", IntegerType(),True),\n",
    "        StructField(\"First_name\", StringType(),True),\n",
    "        StructField(\"Last_name\", StringType(),True),\n",
    "        StructField(\"Gender\", StringType(), True),\n",
    "        StructField(\"salary\", IntegerType(), True),\n",
    "        StructField(\"Date_of_Birth\", StringType(),True),\n",
    "        StructField(\"Age\", IntegerType(),True),\n",
    "        StructField(\"Country\", StringType(),True),\n",
    "        StructField(\"Department_id\", IntegerType(), True),\n",
    "        StructField(\"Date_of_Joining\", StringType(), True),\n",
    "        StructField(\"Manager_id\", IntegerType(), True),\n",
    "        StructField(\"Currency\", StringType(), True),\n",
    "        StructField(\"End_Date\", StringType(), True),\n",
    "    ]\n",
    ")  \n",
    "df = spark.read.format(\"csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".schema(custom_schema)\\\n",
    ".load(\"/mnt/files/Employee.csv\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50b0c949-05ec-40f8-94da-9899585aa2d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "|Employee_id|First_name| Last_name|Gender|salary|Date_of_Birth|Age|  Country|Department_id|Date_of_Joining|Manager_id|Currency|  End_Date|\n",
      "+-----------+----------+----------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "|          1|   Auberon|    Nassie|  Male|105623|   07/11/1988| 60|   Sweden|            4|     23/10/2014|         7|     INR|30/11/2020|\n",
      "|          2|Kristopher|   Winslet|Female| 69531|   29/07/1981| 13|    China|           10|     28/05/2016|         7|     AUD|09/09/2018|\n",
      "|          3|   Kellina|  Lamberto|Female| 96879|   24/07/1984| 27|    India|           12|     21/03/2016|         9|     INR|09/04/2020|\n",
      "|          4|     Tobit|Halksworth|Female| 76070|   29/11/1981| 44|    India|            4|     12/11/2012|        17|     INR|04/10/2019|\n",
      "|          5|     Missy|   Bampkin|  Male| 62228|   03/04/1981| 54|      USA|            7|     14/07/2013|         8|     AUD|20/10/2018|\n",
      "|          6|  Faustina|     Caser|  Male|106837|   27/05/1984| 14|    China|            5|     15/10/2014|         5|     INR|03/04/2020|\n",
      "|          7|      Alic|    Dooler|  Male| 77729|   03/10/1991|-12|   Sweden|           17|     21/06/2014|         9|     AUD|24/02/2018|\n",
      "|          8|     Gabey|   Mainson|  Male| 81590|   05/05/1992| 60|   Sweden|            7|     14/04/2018|        18|     INR|29/03/2019|\n",
      "|          9|    Hammad|    Huckle|  Male| 71206|   08/04/1983|-10|  Germany|           13|     15/05/2018|        19|     AUD|30/12/2020|\n",
      "|         10|     Kanya|    Tipens|  Male| 98642|   21/03/1986| 53|      USA|           11|     31/03/2017|         2|     INR|22/11/2020|\n",
      "|         11|       Ugo|Choulerton|  Male|108740|   29/01/1985| 40|Australia|            9|     28/09/2013|        13|     INR|23/08/2020|\n",
      "|         12|     Kathy|  Milstead|Female|121493|   17/10/1991| -9|   Brazil|            8|     17/09/2010|         8|     INR|02/10/2020|\n",
      "|         13|    Fannie|     Banks|  Male| 67525|   26/08/1985| -6|    China|            8|     08/12/2011|        17|     INR|28/12/2019|\n",
      "|         14|      Loni|  Dalinder|Female|119141|   27/01/1990| -2|   Canada|            8|     14/10/2017|        19|     INR|22/05/2018|\n",
      "|         15|   Melitta|   Stroban|Female|110615|   24/08/1987| 13|  Germany|           11|     22/01/2018|        20|     INR|13/05/2018|\n",
      "|         16|   Pepillo|   Lurcock|  Male|110210|   26/03/1980| 14|  Denmark|            7|     21/09/2017|         7|     AUD|04/11/2020|\n",
      "|         17|       Ben|    Kember|Female|126559|   01/07/1982| 28|    China|            7|     29/12/2018|        12|     AUD|30/03/2018|\n",
      "|         18|    Donnie|   Dodshon|  Male| 70872|   08/01/1983|-13|      USA|            5|     23/01/2012|         7|     INR|11/02/2018|\n",
      "|         19|    Thelma| Blackston|Female| 67683|   05/09/1985| 56|    China|            3|     08/08/2017|        16|     AUD|15/07/2019|\n",
      "|         20|     Stacy|     Albon|  Male| 95195|   02/09/1984| 46|   Sweden|           19|     07/05/2011|        12|     AUD|20/04/2018|\n",
      "+-----------+----------+----------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.filter(df.Department_id.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a980833-173a-4f7d-9d4b-3ab267b52496",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "|Employee_id|First_name|Last_name|Gender|salary|Date_of_Birth|Age|  Country|Department_id|Date_of_Joining|Manager_id|Currency|  End_Date|\n",
      "+-----------+----------+---------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "|         64| Annemarie|  Kirtlan|Female|108098|   04/09/1989| 40|    Japan|         null|     06/02/2010|        16|     INR|11/03/2019|\n",
      "|         65|    Ulises|  Walpole|  Male| 64275|   15/10/1984|  4|      UAE|         null|     11/05/2013|        16|     INR|15/11/2019|\n",
      "|         66|  Consalve|Strangman|Female| 88328|   05/03/1991|  5|Australia|         null|     09/08/2012|         4|     INR|31/12/2019|\n",
      "|         67|    Trixie|  Mullany|Female| 80308|   14/01/1990| 37|  Germany|         null|     21/11/2015|         6|     INR|27/11/2019|\n",
      "|         68|    Rosene|  Chartre|  Male| 89878|   21/12/1991|-12|    India|         null|     17/05/2015|         1|     INR|10/12/2019|\n",
      "|         69|     Adora|    Clegg|Female| 62720|   24/04/1983| -2|   Brazil|         null|     23/01/2014|        10|     INR|22/06/2019|\n",
      "|         70|    Karena|Neaverson|Female| 62003|   08/05/1989|  4|    India|         null|     21/02/2014|        20|     AUD|04/12/2018|\n",
      "|         71|   Novelia| Vasenkov|  Male|122182|   06/12/1980| 17|   Sweden|         null|     21/10/2010|        17|     AUD|27/01/2020|\n",
      "|         72|Wilhelmina|    Yoell|  Male| 75997|   21/04/1986| 42|Australia|         null|     28/01/2015|        17|     INR|12/04/2020|\n",
      "|         73|   Adriano|  Fennick|Female| 96774|   04/07/1991| 60|  Germany|         null|     30/10/2017|        20|     AUD|27/04/2018|\n",
      "|         74|   Crystal|  Luesley|  Male|113232|   06/01/1986| -1|    China|         null|     24/04/2010|         3|     INR|31/08/2020|\n",
      "|         75|     Hinda| McElvine|  Male|112756|   11/08/1989| 26|   Sweden|         null|     11/06/2015|        16|     INR|15/01/2020|\n",
      "+-----------+----------+---------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Department_id > 1\")\\\n",
    ".filter(\"Department_id < 10\")\n",
    "\n",
    "df.filter(\"First_name == 'Ugo'\")\n",
    "df.filter(df[\"Department_id\"].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff38190-5f8c-482d-bb7f-7a3ce8ec7ebc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "|Employee_id|First_name| Last_name|Gender|Date_of_Birth|Age|  Country|Department_id|Date_of_Joining|Manager_id|Currency|  End_Date|\n",
      "+-----------+----------+----------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "|          1|   Auberon|    Nassie|  Male|   07/11/1988| 60|   Sweden|            4|     23/10/2014|         7|     INR|30/11/2020|\n",
      "|          2|Kristopher|   Winslet|Female|   29/07/1981| 13|    China|           10|     28/05/2016|         7|     AUD|09/09/2018|\n",
      "|          3|   Kellina|  Lamberto|Female|   24/07/1984| 27|    India|           12|     21/03/2016|         9|     INR|09/04/2020|\n",
      "|          4|     Tobit|Halksworth|Female|   29/11/1981| 44|    India|            4|     12/11/2012|        17|     INR|04/10/2019|\n",
      "|          5|     Missy|   Bampkin|  Male|   03/04/1981| 54|      USA|            7|     14/07/2013|         8|     AUD|20/10/2018|\n",
      "|          6|  Faustina|     Caser|  Male|   27/05/1984| 14|    China|            5|     15/10/2014|         5|     INR|03/04/2020|\n",
      "|          7|      Alic|    Dooler|  Male|   03/10/1991|-12|   Sweden|           17|     21/06/2014|         9|     AUD|24/02/2018|\n",
      "|          8|     Gabey|   Mainson|  Male|   05/05/1992| 60|   Sweden|            7|     14/04/2018|        18|     INR|29/03/2019|\n",
      "|          9|    Hammad|    Huckle|  Male|   08/04/1983|-10|  Germany|           13|     15/05/2018|        19|     AUD|30/12/2020|\n",
      "|         10|     Kanya|    Tipens|  Male|   21/03/1986| 53|      USA|           11|     31/03/2017|         2|     INR|22/11/2020|\n",
      "|         11|       Ugo|Choulerton|  Male|   29/01/1985| 40|Australia|            9|     28/09/2013|        13|     INR|23/08/2020|\n",
      "|         12|     Kathy|  Milstead|Female|   17/10/1991| -9|   Brazil|            8|     17/09/2010|         8|     INR|02/10/2020|\n",
      "|         13|    Fannie|     Banks|  Male|   26/08/1985| -6|    China|            8|     08/12/2011|        17|     INR|28/12/2019|\n",
      "|         14|      Loni|  Dalinder|Female|   27/01/1990| -2|   Canada|            8|     14/10/2017|        19|     INR|22/05/2018|\n",
      "|         15|   Melitta|   Stroban|Female|   24/08/1987| 13|  Germany|           11|     22/01/2018|        20|     INR|13/05/2018|\n",
      "|         16|   Pepillo|   Lurcock|  Male|   26/03/1980| 14|  Denmark|            7|     21/09/2017|         7|     AUD|04/11/2020|\n",
      "|         17|       Ben|    Kember|Female|   01/07/1982| 28|    China|            7|     29/12/2018|        12|     AUD|30/03/2018|\n",
      "|         18|    Donnie|   Dodshon|  Male|   08/01/1983|-13|      USA|            5|     23/01/2012|         7|     INR|11/02/2018|\n",
      "|         19|    Thelma| Blackston|Female|   05/09/1985| 56|    China|            3|     08/08/2017|        16|     AUD|15/07/2019|\n",
      "|         20|     Stacy|     Albon|  Male|   02/09/1984| 46|   Sweden|           19|     07/05/2011|        12|     AUD|20/04/2018|\n",
      "+-----------+----------+----------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['EMployee_id'])\n",
    "df.drop(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8793dd-98d5-46cf-9f77-5256fc047069",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+-----------------+\n",
      "|Employee_id|First_name| Last_name|Gender|salary|Date_of_Birth|Age|  Country|Department_id|Date_of_Joining|Manager_id|Currency|  End_Date|new_Department_id|\n",
      "+-----------+----------+----------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+-----------------+\n",
      "|          1|   Auberon|    Nassie|  Male|105623|   07/11/1988| 60|   Sweden|            4|     23/10/2014|         7|     INR|30/11/2020|          testing|\n",
      "|          2|Kristopher|   Winslet|Female| 69531|   29/07/1981| 13|    China|           10|     28/05/2016|         7|     AUD|09/09/2018|          testing|\n",
      "|          3|   Kellina|  Lamberto|Female| 96879|   24/07/1984| 27|    India|           12|     21/03/2016|         9|     INR|09/04/2020|          testing|\n",
      "|          4|     Tobit|Halksworth|Female| 76070|   29/11/1981| 44|    India|            4|     12/11/2012|        17|     INR|04/10/2019|          testing|\n",
      "|          5|     Missy|   Bampkin|  Male| 62228|   03/04/1981| 54|      USA|            7|     14/07/2013|         8|     AUD|20/10/2018|          testing|\n",
      "|          6|  Faustina|     Caser|  Male|106837|   27/05/1984| 14|    China|            5|     15/10/2014|         5|     INR|03/04/2020|          testing|\n",
      "|          7|      Alic|    Dooler|  Male| 77729|   03/10/1991|-12|   Sweden|           17|     21/06/2014|         9|     AUD|24/02/2018|          testing|\n",
      "|          8|     Gabey|   Mainson|  Male| 81590|   05/05/1992| 60|   Sweden|            7|     14/04/2018|        18|     INR|29/03/2019|          testing|\n",
      "|          9|    Hammad|    Huckle|  Male| 71206|   08/04/1983|-10|  Germany|           13|     15/05/2018|        19|     AUD|30/12/2020|          testing|\n",
      "|         10|     Kanya|    Tipens|  Male| 98642|   21/03/1986| 53|      USA|           11|     31/03/2017|         2|     INR|22/11/2020|          testing|\n",
      "|         11|       Ugo|Choulerton|  Male|108740|   29/01/1985| 40|Australia|            9|     28/09/2013|        13|     INR|23/08/2020|          testing|\n",
      "|         12|     Kathy|  Milstead|Female|121493|   17/10/1991| -9|   Brazil|            8|     17/09/2010|         8|     INR|02/10/2020|          testing|\n",
      "|         13|    Fannie|     Banks|  Male| 67525|   26/08/1985| -6|    China|            8|     08/12/2011|        17|     INR|28/12/2019|          testing|\n",
      "|         14|      Loni|  Dalinder|Female|119141|   27/01/1990| -2|   Canada|            8|     14/10/2017|        19|     INR|22/05/2018|          testing|\n",
      "|         15|   Melitta|   Stroban|Female|110615|   24/08/1987| 13|  Germany|           11|     22/01/2018|        20|     INR|13/05/2018|          testing|\n",
      "|         16|   Pepillo|   Lurcock|  Male|110210|   26/03/1980| 14|  Denmark|            7|     21/09/2017|         7|     AUD|04/11/2020|          testing|\n",
      "|         17|       Ben|    Kember|Female|126559|   01/07/1982| 28|    China|            7|     29/12/2018|        12|     AUD|30/03/2018|          testing|\n",
      "|         18|    Donnie|   Dodshon|  Male| 70872|   08/01/1983|-13|      USA|            5|     23/01/2012|         7|     INR|11/02/2018|          testing|\n",
      "|         19|    Thelma| Blackston|Female| 67683|   05/09/1985| 56|    China|            3|     08/08/2017|        16|     AUD|15/07/2019|          testing|\n",
      "|         20|     Stacy|     Albon|  Male| 95195|   02/09/1984| 46|   Sweden|           19|     07/05/2011|        12|     AUD|20/04/2018|          testing|\n",
      "+-----------+----------+----------+------+------+-------------+---+---------+-------------+---------------+----------+--------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\n",
    "    \"new_Department_id\",\n",
    "    lit(\"testing\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11c6e170-1e9a-42df-a8f6-c6787e5442ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|max(Department_id)|\n",
      "+------------------+\n",
      "|                20|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max(\"Department_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0d15721-44c1-4c83-951a-85a9629c287b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|sum(Department_id)|\n",
      "+------------------+\n",
      "|             10806|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum(\"Department_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d37974-d704-4726-a374-6535f56de716",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|Department_id|Number of employees|\n",
      "+-------------+-------------------+\n",
      "|            1|                 44|\n",
      "|            2|                 49|\n",
      "|            3|                 46|\n",
      "|            4|                 45|\n",
      "|            5|                 47|\n",
      "|            6|                 37|\n",
      "|            7|                 50|\n",
      "|            8|                 44|\n",
      "|            9|                 49|\n",
      "|           10|                 46|\n",
      "|           11|                 50|\n",
      "|           12|                 46|\n",
      "|           13|                 46|\n",
      "|           14|                 55|\n",
      "|           15|                 56|\n",
      "|           16|                 63|\n",
      "|           17|                 54|\n",
      "|           18|                 60|\n",
      "|           19|                 50|\n",
      "|           20|                 51|\n",
      "+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"Department_id is not null\")\\\n",
    "    .groupBy(\"Department_id\")\\\n",
    "    .agg(\n",
    "        countDistinct(\"Employee_id\").alias(\"Number of employees\"))\\\n",
    "    .orderBy(df[\"Department_id\"]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3dafe6e-ea19-43f0-806c-b1f7e784d28a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "custom_schema = StructType(\n",
    "    [\n",
    "        StructField(\"Country\", StringType(),True),\n",
    "        StructField(\"Gender\", StringType(), True),\n",
    "        StructField(\"Employee_id\", IntegerType(),True),\n",
    "        StructField(\"First_name\", StringType(),True),      \n",
    "        StructField(\"Salary\", IntegerType(), True),        \n",
    "        StructField(\"Department_id\", IntegerType(), True)\n",
    "    ]\n",
    ")  \n",
    "df = spark.read.format(\"csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".schema(custom_schema)\\\n",
    ".load(\"/mnt/files/SampleEmployee.csv\")\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.where(\"Country is not null\")\\\n",
    "    .groupBy(\"Country\")\\\n",
    "    .agg(\n",
    "        max(\"Salary\").alias(\"maximum salary\"),\n",
    "        min(\"Salary\").alias(\"minimum salary\")\n",
    "    )\\\n",
    "    .orderBy(df[\"Country\"]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4974473-b5f3-43dd-9e9a-e50f69b7e43c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+----------+------+-------------+----------+----------+----------+\n",
      "|Country|Gender|Employee_id|First_name|Salary|Department_id|Max Salary|Min Salary|Row_Number|\n",
      "+-------+------+-----------+----------+------+-------------+----------+----------+----------+\n",
      "| Canada|Female|          3|   Kellina| 96879|           12|    106837|     62228|         3|\n",
      "|    USA|  Male|         11|       Ugo|108740|            9|    121493|     67525|         3|\n",
      "+-------+------+-----------+----------+------+-------------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_func_count1 = Window.partitionBy(\"Country\")\\\n",
    "    .orderBy(desc(\"Salary\"))\n",
    "window_count_min = Window.partitionBy(\"Country\")\\\n",
    "    .orderBy(asc(\"Salary\"))\n",
    "\n",
    "df.withColumn(\n",
    "    \"Max Salary\",\n",
    "    max(\"Salary\")\\\n",
    "    .over(window_func_count1)\n",
    ").withColumn(\n",
    "\"Min Salary\",\n",
    "    min(\"Salary\")\\\n",
    "    .over(window_count_min)\n",
    ").withColumn(\n",
    "\"Row_Number\",\n",
    "    row_number()\\\n",
    "    .over(window_func_count1)\n",
    ").where(\n",
    "    \"Row_Number == 3\"\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a1a7f8-41d2-4e72-af32-4a82976e2160",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+----------+------+-------------+----+----------+\n",
      "|Country|Gender|Employee_id|First_name|Salary|Department_id|Rank|Dense Rank|\n",
      "+-------+------+-----------+----------+------+-------------+----+----------+\n",
      "| Canada|Female|          2|Kristopher| 69531|           10|   1|         1|\n",
      "| Canada|Female|          3|   Kellina| 96879|           12|   1|         1|\n",
      "| Canada|Female|          4|     Tobit| 76070|            4|   1|         1|\n",
      "| Canada|  Male|          1|   Auberon|105623|            4|   4|         2|\n",
      "| Canada|  Male|          5|     Missy| 62228|            7|   4|         2|\n",
      "| Canada|  Male|          6|  Faustina|106837|            5|   4|         2|\n",
      "| Canada|  Male|          7|      Alic| 77729|           17|   4|         2|\n",
      "|    USA|Female|         12|     Kathy|121493|            8|   1|         1|\n",
      "|    USA|Female|         14|      Loni|119141|            8|   1|         1|\n",
      "|    USA|  Male|          8|     Gabey| 81590|            7|   3|         2|\n",
      "|    USA|  Male|          9|    Hammad| 71206|           13|   3|         2|\n",
      "|    USA|  Male|         10|     Kanya| 98642|           11|   3|         2|\n",
      "|    USA|  Male|         11|       Ugo|108740|            9|   3|         2|\n",
      "|    USA|  Male|         13|    Fannie| 67525|            8|   3|         2|\n",
      "+-------+------+-----------+----------+------+-------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rank based on country\n",
    "\n",
    "window_func_count2 = Window.partitionBy(\"Country\")\\\n",
    "    .orderBy(\"Gender\")\n",
    "\n",
    "df.withColumn(\n",
    "    \"Rank\",\n",
    "    rank().over(window_func_count2)\n",
    ").withColumn(\n",
    "    \"Dense Rank\",\n",
    "    dense_rank().over(window_func_count2)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "979f10d5-214f-4394-ac7c-d202bfd23b04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+----------+------+-------------+----+\n",
      "|Country|Gender|Employee_id|First_name|Salary|Department_id|Rank|\n",
      "+-------+------+-----------+----------+------+-------------+----+\n",
      "| Canada|Female|          2|Kristopher| 69531|           10|   1|\n",
      "| Canada|Female|          3|   Kellina| 96879|           12|   1|\n",
      "| Canada|Female|          4|     Tobit| 76070|            4|   1|\n",
      "| Canada|  Male|          1|   Auberon|105623|            4|   4|\n",
      "| Canada|  Male|          5|     Missy| 62228|            7|   4|\n",
      "| Canada|  Male|          6|  Faustina|106837|            5|   4|\n",
      "| Canada|  Male|          7|      Alic| 77729|           17|   4|\n",
      "|    USA|Female|         12|     Kathy|121493|            8|   1|\n",
      "|    USA|Female|         14|      Loni|119141|            8|   1|\n",
      "|    USA|  Male|          8|     Gabey| 81590|            7|   4|\n",
      "|    USA|  Male|          9|    Hammad| 71206|           13|   4|\n",
      "|    USA|  Male|         10|     Kanya| 98642|           11|   4|\n",
      "|    USA|  Male|         11|       Ugo|108740|            9|   4|\n",
      "|    USA|  Male|         13|    Fannie| 67525|            8|   4|\n",
      "+-------+------+-----------+----------+------+-------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\n",
    "    \"Rank\",\n",
    "    when(\n",
    "        df['Gender'] == \"Female\",\n",
    "        lit(1)\n",
    "    ).otherwise(\n",
    "        4\n",
    "    )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dcc07ae-4d62-443d-8325-121de6ec9326",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+--------------+\n",
      "|Country|Gender|maximum salary|minimum salary|\n",
      "+-------+------+--------------+--------------+\n",
      "| Canada|Female|         96879|         69531|\n",
      "| Canada|  Male|        106837|         62228|\n",
      "|    USA|Female|        121493|        119141|\n",
      "|    USA|  Male|        108740|         67525|\n",
      "+-------+------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"Country is not null\")\\\n",
    "    .groupBy(\"Country\", \"Gender\")\\\n",
    "    .agg(\n",
    "        max(\"Salary\").alias(\"maximum salary\"),\n",
    "        min(\"Salary\").alias(\"minimum salary\")\n",
    "    )\\\n",
    "    .orderBy(df[\"Country\"]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7f6688a-bc4f-4482-862a-a7dee15b0f2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+----------+------+-------------+---------------------------+\n",
      "|Country|Gender|Employee_id|First_name|Salary|Department_id|Rank per country per gender|\n",
      "+-------+------+-----------+----------+------+-------------+---------------------------+\n",
      "| Canada|Female|          2|Kristopher| 69531|           10|                      69531|\n",
      "| Canada|Female|          4|     Tobit| 76070|            4|                      76070|\n",
      "| Canada|Female|          3|   Kellina| 96879|           12|                      96879|\n",
      "| Canada|  Male|          5|     Missy| 62228|            7|                      62228|\n",
      "| Canada|  Male|          7|      Alic| 77729|           17|                      77729|\n",
      "| Canada|  Male|          1|   Auberon|105623|            4|                     105623|\n",
      "| Canada|  Male|          6|  Faustina|106837|            5|                     106837|\n",
      "|    USA|Female|         14|      Loni|119141|            8|                     119141|\n",
      "|    USA|Female|         12|     Kathy|121493|            8|                     121493|\n",
      "|    USA|  Male|         13|    Fannie| 67525|            8|                      67525|\n",
      "|    USA|  Male|          9|    Hammad| 71206|           13|                      71206|\n",
      "|    USA|  Male|          8|     Gabey| 81590|            7|                      81590|\n",
      "|    USA|  Male|         10|     Kanya| 98642|           11|                      98642|\n",
      "|    USA|  Male|         11|       Ugo|108740|            9|                     108740|\n",
      "+-------+------+-----------+----------+------+-------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_func_count2 = Window.partitionBy(\"Country\", \"Gender\")\\\n",
    "    .orderBy(\"Salary\")\n",
    "\n",
    "df.withColumn(\n",
    "    \"Rank per country per gender\",\n",
    "    max(\"Salary\").over(window_func_count2)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f3a50d1-88c0-4996-bcc6-d314b46da292",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "748811b3-4a89-4bb0-8f15-fac7191f2698",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_emp = spark.read.format(\"csv\")\\\n",
    "    .options(header='true', delimeter=',')\\\n",
    "    .load(\"/mnt/files/Sample_data4jOIN.csv\")\n",
    "\n",
    "df_dep = spark.read.format(\"csv\")\\\n",
    "    .options(header='true', delimeter=',')\\\n",
    "    .load(\"/mnt/files/Department.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caa4f802-1172-4522-a6f9-82cc0bbd7c33",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+----------+\n",
      "|Employee_id|Department_id|Department_id|First_Name|\n",
      "+-----------+-------------+-------------+----------+\n",
      "|          1|            1|            1|   Auberon|\n",
      "|          2|            2|            2|Kristopher|\n",
      "|          3|            3|            3|   Kellina|\n",
      "|          4|            4|            4|     Tobit|\n",
      "|          5|            5|            5|     Missy|\n",
      "|          6|            6|            6|  Faustina|\n",
      "|          7|            7|            7|      Alic|\n",
      "|          8|            8|            8|     Gabey|\n",
      "|          9|            9|            9|    Hammad|\n",
      "|         10|           10|           10|     Kanya|\n",
      "+-----------+-------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_emp.join(\n",
    "    df_dep, \n",
    "    df_emp.Department_id == df_dep.Department_id,\n",
    "    \"inner\"\n",
    ").select(\n",
    "    df_emp.Employee_id, df_emp.Department_id, df_dep.Department_id, df_emp.First_Name\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63fdb371-5b00-4216-8338-4659e06933c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+----------+\n",
      "|Employee_id|Department_id|Department_id|First_Name|\n",
      "+-----------+-------------+-------------+----------+\n",
      "|          1|            1|            1|   Auberon|\n",
      "|          2|            2|            2|Kristopher|\n",
      "|          3|            3|            3|   Kellina|\n",
      "|          4|            4|            4|     Tobit|\n",
      "|          5|            5|            5|     Missy|\n",
      "|          6|            6|            6|  Faustina|\n",
      "|          7|            7|            7|      Alic|\n",
      "|          8|            8|            8|     Gabey|\n",
      "|          9|            9|            9|    Hammad|\n",
      "|         10|           10|           10|     Kanya|\n",
      "|         11|           15|         null|       Ugo|\n",
      "+-----------+-------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.join(\n",
    "    df_dep, \n",
    "    df_emp.Department_id == df_dep.Department_id,\n",
    "    \"left\"\n",
    ").select(\n",
    "    df_emp.Employee_id, df_emp.Department_id, df_dep.Department_id, df_emp.First_Name\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5f87d7f-eb3f-46a3-882f-3da103c3ac60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+----------+\n",
      "|Employee_id|Department_id|Department_id|First_Name|\n",
      "+-----------+-------------+-------------+----------+\n",
      "|          1|            1|            1|   Auberon|\n",
      "|          2|            2|            2|Kristopher|\n",
      "|          3|            3|            3|   Kellina|\n",
      "|          4|            4|            4|     Tobit|\n",
      "|          5|            5|            5|     Missy|\n",
      "|          6|            6|            6|  Faustina|\n",
      "|          7|            7|            7|      Alic|\n",
      "|          8|            8|            8|     Gabey|\n",
      "|          9|            9|            9|    Hammad|\n",
      "|         10|           10|           10|     Kanya|\n",
      "|       null|         null|           11|      null|\n",
      "|       null|         null|           12|      null|\n",
      "|       null|         null|           13|      null|\n",
      "+-----------+-------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.join(\n",
    "    df_dep, \n",
    "    df_emp.Department_id == df_dep.Department_id,\n",
    "    \"right\"\n",
    ").select(\n",
    "    df_emp.Employee_id, df_emp.Department_id, df_dep.Department_id, df_emp.First_Name\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "329819a8-2d1e-46d4-8557-dc2d2cc62dda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+----------+\n",
      "|Employee_id|Department_id|Department_id|First_Name|\n",
      "+-----------+-------------+-------------+----------+\n",
      "|          1|            1|            1|   Auberon|\n",
      "|         10|           10|           10|     Kanya|\n",
      "|       null|         null|           11|      null|\n",
      "|       null|         null|           12|      null|\n",
      "|       null|         null|           13|      null|\n",
      "|         11|           15|         null|       Ugo|\n",
      "|          2|            2|            2|Kristopher|\n",
      "|          3|            3|            3|   Kellina|\n",
      "|          4|            4|            4|     Tobit|\n",
      "|          5|            5|            5|     Missy|\n",
      "|          6|            6|            6|  Faustina|\n",
      "|          7|            7|            7|      Alic|\n",
      "|          8|            8|            8|     Gabey|\n",
      "|          9|            9|            9|    Hammad|\n",
      "+-----------+-------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.join(\n",
    "    df_dep, \n",
    "    df_emp.Department_id == df_dep.Department_id,\n",
    "    \"full\"\n",
    ").select(\n",
    "    df_emp.Employee_id, df_emp.Department_id, df_dep.Department_id, df_emp.First_Name\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bcd3185-9db0-4a66-8585-4cdca5ce5e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_emp.createOrReplaceTempView(\"emp\")\n",
    "df_dep.createOrReplaceTempView(\"dept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d0d087b-b2c3-46bf-8688-7dd5af9deaca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|Employee_id|Department_id|\n",
      "+-----------+-------------+\n",
      "|          1|            1|\n",
      "|          2|            2|\n",
      "|          3|            3|\n",
      "|          4|            4|\n",
      "|          5|            5|\n",
      "|          6|            6|\n",
      "|          7|            7|\n",
      "|          8|            8|\n",
      "|          9|            9|\n",
      "|         10|           10|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_1 = spark.sql(\n",
    "    \"select emp.Employee_id, emp.Department_id from emp INNER JOIN dept on emp.Department_id = dept.Department_id\"\n",
    ")\n",
    "query_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77386fa1-5180-448f-9fef-9c1c9b3f1c90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+\n",
      "|Employee_id|Department_id|Department_id|\n",
      "+-----------+-------------+-------------+\n",
      "|          1|            1|            1|\n",
      "|          2|            2|            2|\n",
      "|          3|            3|            3|\n",
      "|          4|            4|            4|\n",
      "|          5|            5|            5|\n",
      "|          6|            6|            6|\n",
      "|          7|            7|            7|\n",
      "|          8|            8|            8|\n",
      "|          9|            9|            9|\n",
      "|         10|           10|           10|\n",
      "|         11|           15|         null|\n",
      "+-----------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_1 = spark.sql(\n",
    "    \"select emp.Employee_id, emp.Department_id, dept.Department_id from emp LEFT JOIN dept on emp.Department_id = dept.Department_id\"\n",
    ")\n",
    "query_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d989668b-ed66-4d38-ad78-a482813c5161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3389445316573367,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "udemy-pyspark",
   "notebookOrigID": 3389445316573366,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
